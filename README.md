![](https://img.shields.io/github/stars/pandao/editor.md.svg) ![](https://img.shields.io/github/forks/pandao/editor.md.svg) ![](https://img.shields.io/github/tag/pandao/editor.md.svg) ![](https://img.shields.io/github/release/pandao/editor.md.svg) ![](https://img.shields.io/github/issues/pandao/editor.md.svg) ![](https://img.shields.io/bower/v/editor.md.svg)


### Introduction
The project aims to detect and recognize faces. The final objective is to code the identified faces and export the data for application in other projects, such as searching social networks by facial recognition, searching in databases and applications in Marketing, how to qualify Leads to prospect possible customers who frequent your establishment.

The code is divided into four modules, making the system easier to read and understand. We ask that, before using these modules, you fully understand how each one communicates with the other.

### Modules
In this topic we will explain the basics of how all modules work to facilitate the use and reproduction of the code. [Opencv-python](https://docs.opencv.org/4.x/d6/d00/tutorial_py_root.html) and [Mediapipe](https://google.github.io/mediapipe/) are essential for understanding. We recommend that you have a base of usage for each extension.

#### [main.py](https://github.com/RP11-AI/face-recognition-3SN/blob/main/py/main.py)
We start by activating the Detector class of the [detector_module.py](https://github.com/RP11-AI/face-recognition-3SN/blob/main/py/detector_module.py) module. In this segmentation are most of the system properties, including whether you will proceed with the treatment and encoding of the exported images. Pay attention to the method:

<pre><code>with detection_system.mp_face_detector.FaceDetection(min_detection_confidence=0.2,
                                                     model_selection=1) as machine_face_detector:
</code></pre>

We recommend that you read the [Mediapipe Framework Concepts](https://google.github.io/mediapipe/framework_concepts/gpu.html) documentation to understand how it works and the need to reduce processing costs. You will better understand how the [*detector_module.py*](https://github.com/RP11-AI/face-recognition-3SN/blob/main/py/detector_module.py) module works. In the loop are the system specs and the video/camera frame refresh feature. Afterwards, the treatment of the exported images and the coding of the faces.

#### [detector_module.py](https://github.com/RP11-AI/face-recognition-3SN/blob/main/py/detector_module.py)
In order, we will continue to explain the construction of the `Detector()`. Pay attention to the *__init__* function and its parameters. Some internal processing parameters such as `mp.solutions.face_detection` should have more of your attention.

| Function name  | Description                    |
| -------------  | ------------------------------ |
| `Detector()`   | Initial Parameters             |
| `stack_image()`| Generate a generic image stack |
| `Capture()`    | Process the image with the specified machine |
| `Bbox()`       | Extract and save the clippings of the original video with the bounding boxes |
| `Grid()`       | Generate an image grid simultaneously with the video |
| `VideoOutput()`| Display window containing processed videos |
| `RecordVideo()`| Records videos |
| `ReleaseCap()` | Release the camera/video used and destroy all windows generated by opencv |

In the static methods, we have the `stack_image()` function which is a generalization of ways of stacking images. It will serve to show the user the soft search being performed on the video/camera. In the `Capture()`, we have the machine parameter that will be used an argument of the class itself `self.mp_face_detection` and after executed in the [main.py](https://github.com/RP11-AI/face-recognition-3SN/blob/main/py/main.py) file in the with operator. In addition, we have the treatment of each frame, based on what is recommended by Mediapipe and the execution of the face search.

![Face Detection with Mediapipe](https://github.com/RP11-AI/face-recognition-3SN/blob/main/readme-data/output_video.gif?raw=true)

### Face Auth
In the second process, a more robust face detection process is performed. In [faceAuth.py](https://github.com/RP11-AI/face-search-by-recognition/blob/main/py/faceAuth.py) the detection will be performed by the png images. As the images are focused on possible faces, a more robust detection is more efficient. Images in which a face is not identified the system will delete.

### Face Recognition
In the module [faceRecognition.py](https://github.com/RP11-AI/face-search-by-recognition/blob/main/py/faceRecognition.py) the images that are still in the folder will be encoded. While the images are being encoded, they will be compared with themselves in a search engine to organize identical faces in the same specific directory.

![All Text](https://github.com/RP11-AI/face-search-by-recognition/blob/main/readme-data/2022-07-19%20120423.png?raw=true)

After the process is finished, all the images will be organized in folders.

![All Text](https://github.com/RP11-AI/face-search-by-recognition/blob/main/readme-data/2022-07-19%20120214.png?raw=true)

### Decoder
With the detections already organized, the module [decoder.py](https://github.com/RP11-AI/face-search-by-recognition/blob/main/py/decoder.py) will encode all the images in the folder and generate a master encoding of the identified person. Master encoding will be exported in csv.

![All text](https://github.com/RP11-AI/face-search-by-recognition/blob/main/readme-data/2022-07-19%20120319.png?raw=true)

In this module it will be possible to decode the csv file for future use by the identified people.

![All text](https://github.com/RP11-AI/face-search-by-recognition/blob/main/readme-data/2022-07-19%20120503.png?raw=true)
